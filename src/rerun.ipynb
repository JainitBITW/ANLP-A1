{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home2/jainit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home2/jainit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home2/jainit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Device:  cuda\n",
      "cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home2/jainit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home2/jainit/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home2/jainit/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing the libraries \n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn.functional as F\n",
    "import nltk \n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import random\n",
    "from torch import cuda\n",
    "import config_hp as hp\n",
    "from pprint import pprint\n",
    "import pickle \n",
    "from  data_maker import *\n",
    "WANDB_SILENT = \"true\"\n",
    "import wandb\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import argparse\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "import LSTM\n",
    "import NNLM\n",
    "\n",
    "\n",
    "\n",
    "glove_embeddings = pickle.load(open('../data/embeddings.pkl','rb'))\n",
    "\n",
    "model = LSTM.LSTM_LM(glove_embeddings, hp.HIDDEN_LAYER, hp.NUM_LAYERS, hp.DROPOUT).to(device)\n",
    "model.load_state_dict(torch.load('../data/models/LSTM.pt'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Loaded\n",
      "Enter the starting word\n",
      "Enter the number of words to generate\n",
      "i am a man of <OOV> '' <EOS> the count <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> <EOS> '' <EOS> the count `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am \n",
      "Enter the starting word\n",
      "Enter the number of words to generate\n",
      "hi\n",
      "100 presentiment conquer imperturbable conquer excused 'have `` `` i am sure to be sure '' <EOS> said `` i am not mistaken that i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i \n",
      "Enter the starting word\n",
      "Enter the number of words to generate\n",
      "hi\n",
      "you  presentiment conquer imperturbable conquer excused 'have `` `` i am sure to be sure '' <EOS> said `` i am not mistaken that i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` i am not mistaken to you '' <EOS> he said `` \n",
      "Enter the starting word\n",
      "Enter the number of words to generate\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m word \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m()\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEnter the number of words to generate\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m num_words \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(\u001b[39minput\u001b[39;49m())\n\u001b[1;32m      9\u001b[0m generated_text \u001b[39m=\u001b[39m LSTM\u001b[39m.\u001b[39mLSTM_LM\u001b[39m.\u001b[39mgenerate_text(model , word_to_id, word, num_words)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(generated_text)\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "\n",
    "word_to_id = json.load(open('../data/word_to_id.json','r'))\n",
    "model.eval()\n",
    "print(\"Model Loaded\")\n",
    "while(True):\n",
    "    print(\"Enter the starting word\")\n",
    "    word = input()\n",
    "    print(\"Enter the number of words to generate\")\n",
    "    num_words = int(input())\n",
    "    generated_text = LSTM.LSTM_LM.generate_text(model , word_to_id, word, num_words)\n",
    "    print(generated_text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
