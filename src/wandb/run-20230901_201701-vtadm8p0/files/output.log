
The Device is cuda
/home2/jainit/anlp/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
Epoch: 1, Loss: 5.509924208081739
/home2/jainit/anlp/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:389: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.
  warnings.warn("To get the last learning rate computed by the scheduler, "
VALID: Epoch: 1, Loss: 5.0293126075176415
Epoch: 2, Loss: 4.896934281918961
VALID: Epoch: 2, Loss: 4.816913576193922
Epoch: 3, Loss: 4.646187099974594
VALID: Epoch: 3, Loss: 4.789445060837744
Epoch: 4, Loss: 4.520099595443672
VALID: Epoch: 4, Loss: 4.866255399126726